# Mosaic: LLM & VLM Integration with Whisper Transcription

## ğŸ—ï¸ Structure

```shell
.
â”œâ”€â”€ 1.main.py                    # actual main at the moment
â”œâ”€â”€ 2.intention_predict.py       # real time video feed: gesture + head motion detection(moving region of interest along the head direction) + YOLO + speech interaction
â”œâ”€â”€ 3.speech_detection.py        
â”œâ”€â”€ gesture.py                   
â”œâ”€â”€ main.py                      
â”œâ”€â”€ run.sh                       # bash script to avoid warning
â”œâ”€â”€ requirements.txt             # dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ yolo_model/                  # YOLO models
â”‚   â”œâ”€â”€ yolo11m.pt
â”‚   â”œâ”€â”€ yolo11n.pt
â”‚   â”œâ”€â”€ yolo12x.pt
â”‚   â””â”€â”€ yolov8x-oiv7.pt
â”œâ”€â”€ images/                      # rgb images and depth maps
â”‚   â”œâ”€â”€ depth.npy
â”‚   â”œâ”€â”€ depth.png
â”‚   â”œâ”€â”€ rgb.png
â”‚   â”œâ”€â”€ example1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ src/
    â”œâ”€â”€ utils.py
    â”œâ”€â”€ execute/                 
    â”‚   â””â”€â”€ actions.py
    â”œâ”€â”€ intention/               
    â”‚   â””â”€â”€ intention_predict.py
    â”œâ”€â”€ mistral_ai/
    â”‚   â”œâ”€â”€ llm.py               
    â”‚   â”œâ”€â”€ vlm.py               
    â”‚   â”œâ”€â”€ mistral.py           # Mistral API
    â”‚   â”œâ”€â”€ prompts/
    â”‚   â”‚   â”œâ”€â”€ plan_prompt.py
    â”‚   â”‚   â””â”€â”€ vision_prompt.py
    â”‚   â””â”€â”€ scripts/
    â”‚       â”œâ”€â”€ llm_script.txt
    â”‚       â”œâ”€â”€ llm_script.json
    â”‚       â”œâ”€â”€ vlm_script.txt
    â”‚       â””â”€â”€ vlm_script.json
    â”œâ”€â”€ pixel_world/
    â”‚   â””â”€â”€ pixel_world.py       # image coordinate and world coordinate conversion
    â”œâ”€â”€ transcribe/
    â”‚   â”œâ”€â”€ stt.py               # speech to text
    â”‚   â”œâ”€â”€ tts.py               # text to speech
    â”‚   â””â”€â”€ transcription.txt
    â””â”€â”€ VLM_agent/
```

## ğŸ”§ Installation guide

1. **Clone the repo**  
   ```bash
   git clone https://github.com/Haoqingtianxia1997/Mosaic.git
   cd Mosaic
   ```

2. **Install system dependencies(for Ubuntu 22.04)**  
   ```bash
   sudo apt update
   sudo apt install portaudio19-dev python3-dev pulseaudio pulseaudio-utils
   ```

3. **Install Python dependencies**  
   ```bash
   conda create -n mosaic python=3.11
   conda activate mosaic
   pip install -r requirements.txt
   ```

4. **Set environment variables**  
   Add the following lines to `~/.bashrc`, `~/.zshrc` or `~/.config/fish/config.fish`:  
   ```bash
   export MISTRAL_API_KEY="your_mistral_api_key_here"
   ```

## ğŸ¯ Run

1. **Bash script**  
   ```bash
   ./run.sh
   ```

2. **Main script**  
   ```bash
   python3 1.main.py
   ```

3. **Test intention detection**  
   ```bash
   python3 2.intention_predict.py
   ```


## ğŸ“ TODO

- [ ] Incorporate gaze detection
- [ ] ROS2 service for movement control
- [ ] Camera calibration