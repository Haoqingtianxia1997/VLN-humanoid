from src.VLM_agent.OwlViT_FastSAM_SAM import find_object_central_pixel
from src.mistral_ai.vlm import run_mistral_vlm



def VLM_agent(user_prompt: str, image_path) -> list:
    """
    å¯åŠ¨ VLM Agentï¼Œå¤„ç†è§†è§‰ä»»åŠ¡ã€‚
    """
    if user_prompt == "user person":
        return True, (0, 0, 0)  # è¿”å›ä¸€ä¸ªé»˜è®¤çš„åæ ‡ç‚¹
    elif user_prompt == "home":
        return True, (1, 1, 1)  # è¿”å›ä¸€ä¸ªé»˜è®¤çš„åæ ‡ç‚¹
    elif user_prompt == "spoon rest":
        return True, (2, 2, 2) # è¿”å›ä¸€ä¸ªé»˜è®¤çš„åæ ‡ç‚¹

    print("ğŸŸ¢ Starting VLM Agent...")
    if_find , target_label, target_text = run_mistral_vlm(user_prompt, image_path)  # è°ƒç”¨ VLM æ¨¡å‹å¤„ç†è§†è§‰ä»»åŠ¡
    
    if not if_find:
        print("âŒ No target found at the moment.")
        return False, None
    
    target_prompt, box_center_point, seg_center_point, bbox, score = find_object_central_pixel(target_label, target_text, image_path, is_sam = True, if_translate = False)  # è°ƒç”¨å‡½æ•°å¤„ç†å›¾åƒä¸­çš„ç›®æ ‡æ£€æµ‹
    print(f"ğŸ” Detected target: {target_label}")
    print(f"ğŸ“ Target prompt: {target_prompt}")
    print(f"ğŸ“ Bounding box: {bbox}")
    print(f"ğŸ¯ Box center point: {box_center_point}")
    print(f"ğŸ¯ Segmentation center point: {seg_center_point}")
    print(f"ğŸ“Š Detection score: {score}")

    print("âœ… VLM Agent completed.")

    return True, box_center_point, seg_center_point